{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "import xgboost as xgb\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.tree import GradientBoostedTrees\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from operator import add\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "f=sc.textFile(\"train.csv\")\n",
    "trainRecord=f.filter(lambda x:\".\" in x).map(lambda x:x.split(\",\")).map(lambda x:[x[a] for a in [0,1,2,5,6,7,8,10,12]])\n",
    "testRecord=sc.textFile(\"test.csv\").filter(lambda x:\".\" in x).map(lambda x:x.split(\",\")).map(lambda x:[x[a] for a in [0,1,4,5,6,7,9,11]])\n",
    "def trainStand(l):\n",
    "#     gender\n",
    "    l[3]=[0,1] if l[3]==\"male\" else [1,0]\n",
    "#     class\n",
    "    if l[-1]!=\"\":\n",
    "        l[-1]=l[-1].replace('S',\"0\").replace(\"C\",\"1\").replace(\"Q\",\"2\")\n",
    "    else:\n",
    "        l[-1]=\"0\"\n",
    "    vec=np.zeros(3)\n",
    "    vec[int(l[-1])]=1\n",
    "    l=l[:3]+l[3]+l[4:-1]+(vec.tolist())\n",
    "    l[5]=\"30\" if l[5]==\"\" else l[5]\n",
    "    return l\n",
    "def testStand(l):\n",
    "#     gender\n",
    "    l[2]=[0,1] if l[2]==\"male\" else [1,0]\n",
    "#     class\n",
    "    if l[-1]!=\"\":\n",
    "        l[-1]=l[-1].replace('S',\"0\").replace(\"C\",\"1\").replace(\"Q\",\"2\")\n",
    "    else:\n",
    "        l[-1]=\"0\"\n",
    "    vec=np.zeros(3)\n",
    "    vec[int(l[-1])]=1\n",
    "    l=l[:2]+l[2]+l[3:-1]+(vec.tolist())\n",
    "    l[7]=7.5 if l[7]==\"\" else l[7]\n",
    "    l[4]=\"30\" if l[4]==\"\" else l[4]\n",
    "    return l\n",
    "train=trainRecord.map(trainStand).map(lambda x:[float(a) for a in x]).map(lambda x:LabeledPoint(x[1],x[2:]))\n",
    "test=testRecord.map(testStand).map(lambda x:[float(a) for a in x]).map(lambda x:LabeledPoint(x[0],x[1:]))\n",
    "# ageTrain=oktrain.filter(lambda x:x[5]!=\"\").map(lambda x:[float(a) for a in x]).map(lambda x:LabeledPoint(x[5],x[2:5]+x[6:]))\n",
    "# ageTest=oktrain.filter(lambda x:x[5]==\"\").map(lambda x:[float(a) for a in x if a!=\"\"]).map(lambda x:LabeledPoint(x[0],x[2:]))\n",
    "# tageTrain=oktest.filter(lambda x:x[4]!=\"\").map(lambda x:[float(a) for a in x]).map(lambda x:LabeledPoint(x[4],x[1:4]+x[5:]))\n",
    "# tageTest=oktest.filter(lambda x:x[4]==\"\").map(lambda x:[float(a) for a in x if a!=\"\"]).map(lambda x:LabeledPoint(x[0],x[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=train\n",
    "data=np.array(t.map(lambda x:x.features).collect())\n",
    "label=np.array(t.map(lambda x:x.label).collect())\n",
    "xgtrain = xgb.DMatrix( data, label=label)\n",
    "t=test\n",
    "data=np.array(t.map(lambda x:x.features).collect())\n",
    "label=np.array(t.map(lambda x:x.label).collect())\n",
    "xgtest = xgb.DMatrix( data, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dee08453196a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[1;31m# training model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[1;31m# early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[1;31m# cvresult=xgboost.cv(params, xgtrain, num_boost_round=100, nfold=5,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[1;31m#                 metrics={'error'}, seed=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\soft\\python\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0mcvfolds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmknfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[1;31m# setup callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\soft\\python\\lib\\site-packages\\xgboost-0.6-py3.5.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mmknfold\u001b[0;34m(dall, nfold, param, seed, evals, fpreproc, stratified, folds)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratified\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mrandidx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mkstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandidx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0midset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandidx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mkstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mkstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mfolds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from pyspark.mllib.util import MLUtils\n",
    "t,tt=train.randomSplit([0.7,0.3])\n",
    "data=np.array(t.map(lambda x:x.features).collect())\n",
    "label=np.array(t.map(lambda x:x.label).collect())\n",
    "xgtrain = xgb.DMatrix( data, label=label)\n",
    "t=tt\n",
    "data=np.array(t.map(lambda x:x.features).collect())\n",
    "label=np.array(t.map(lambda x:x.label).collect())\n",
    "xgtest = xgb.DMatrix( data, label=label)\n",
    "params={\n",
    "'booster':'gbtree',\n",
    "# 这里手写数字是0-9，是一个多类的问题，因此采用了multisoft多分类器，\n",
    "'objective': 'binary:logistic', \n",
    "'subsample':1,\n",
    "'gamma':0.5,  # 在树的叶子节点下一个分区的最小损失，越大算法模型越保守 。[0:]\n",
    "'max_depth':3, # 构建树的深度 [1:]\n",
    "#'lambda':450,  # L2 正则项权重\n",
    "'colsample_bytree':0.8, # 构建树树时的采样比率 (0:1]\n",
    "'min_child_weight':9,\n",
    "'eta': 0.1, # 如同学习率\n",
    "'seed':710,\n",
    "}\n",
    "plst = list(params.items())\n",
    "\n",
    "# return 训练和验证的错误率\n",
    "# watchlist = [(xgtrain, 'train')]\n",
    "watchlist = [(xgtrain, 'train'),(xgtest, 'val')]\n",
    "num_rounds=3000\n",
    "# xgb.cv\n",
    "# training model \n",
    "# early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练\n",
    "model = xgb.cv(plst, xgtrain, num_rounds, watchlist,early_stopping_rounds=100)\n",
    "# cvresult=xgboost.cv(params, xgtrain, num_boost_round=100, nfold=5,\n",
    "#                 metrics={'error'}, seed=0)\n",
    "#model.save_model('./model/xgb.model') # 用于存储训练出的模型\n",
    "preds = model.predict(xgtest,ntree_limit=model.best_iteration)\n",
    "# def prob2bool(l):\n",
    "#     if l>0.5:\n",
    "#         return 1\n",
    "#     return 0\n",
    "# result=sc.parallelize(preds).map(prob2bool).zipWithIndex().map(lambda x: (str(x[1]+892)+\",\"+str(x[0])+\"\\n\"))\n",
    "# a=result.collect()\n",
    "# file_object = open('thefile4.csv', 'w')\n",
    "# file_object.write(\"PassengerId,Survived\\n\")\n",
    "# file_object.writelines(a)\n",
    "# file_object.close( )\n",
    "# result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-error-mean': [0.20224700000000001,\n",
       "  0.20224699999999998,\n",
       "  0.1988762,\n",
       "  0.20337060000000001,\n",
       "  0.1988762,\n",
       "  0.1988762,\n",
       "  0.1977526,\n",
       "  0.20112340000000001,\n",
       "  0.1988762,\n",
       "  0.19438179999999999,\n",
       "  0.1988762,\n",
       "  0.1955054,\n",
       "  0.1955054,\n",
       "  0.1955054,\n",
       "  0.1955054,\n",
       "  0.1955054,\n",
       "  0.196629,\n",
       "  0.1977526,\n",
       "  0.1988762,\n",
       "  0.19999980000000001,\n",
       "  0.1977526,\n",
       "  0.196629,\n",
       "  0.1977526,\n",
       "  0.196629,\n",
       "  0.19438179999999999,\n",
       "  0.19213459999999999,\n",
       "  0.19213459999999999,\n",
       "  0.19101099999999999,\n",
       "  0.19101100000000001,\n",
       "  0.1831458,\n",
       "  0.18089859999999999,\n",
       "  0.17752780000000001,\n",
       "  0.17528060000000001,\n",
       "  0.17865139999999999,\n",
       "  0.17977499999999996,\n",
       "  0.17977499999999996,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.1831458,\n",
       "  0.18426939999999997,\n",
       "  0.18202220000000002,\n",
       "  0.17977500000000002,\n",
       "  0.17977500000000002,\n",
       "  0.17977500000000002,\n",
       "  0.17977500000000002,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.18426940000000003,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.17977500000000002,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.1831458,\n",
       "  0.18202220000000002,\n",
       "  0.18202220000000002,\n",
       "  0.1831458,\n",
       "  0.18202219999999997,\n",
       "  0.185393,\n",
       "  0.185393,\n",
       "  0.18202219999999997,\n",
       "  0.18651659999999998,\n",
       "  0.18426939999999997,\n",
       "  0.185393,\n",
       "  0.18426939999999997,\n",
       "  0.18426940000000003,\n",
       "  0.18426940000000003,\n",
       "  0.18202220000000002,\n",
       "  0.18651659999999998,\n",
       "  0.18426939999999997,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.18426940000000003,\n",
       "  0.1831458,\n",
       "  0.18426940000000003,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.18426940000000003,\n",
       "  0.1831458,\n",
       "  0.18202220000000002,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.1831458,\n",
       "  0.18426939999999997,\n",
       "  0.18426939999999997,\n",
       "  0.18426939999999997,\n",
       "  0.185393,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999,\n",
       "  0.18089859999999999],\n",
       " 'test-error-std': [0.017040237697872648,\n",
       "  0.025374460577517702,\n",
       "  0.022075237406650919,\n",
       "  0.026446403079435962,\n",
       "  0.026731291763773778,\n",
       "  0.026254759952435289,\n",
       "  0.020534539309173701,\n",
       "  0.027384508654346894,\n",
       "  0.026254759952435289,\n",
       "  0.020900168137122727,\n",
       "  0.026254759952435289,\n",
       "  0.020534539309173705,\n",
       "  0.020534539309173705,\n",
       "  0.020534539309173705,\n",
       "  0.020534539309173705,\n",
       "  0.020534539309173705,\n",
       "  0.020411207627183649,\n",
       "  0.022861877907118654,\n",
       "  0.022639912671209666,\n",
       "  0.020595928203409521,\n",
       "  0.024719200000000007,\n",
       "  0.021020631198896002,\n",
       "  0.025720379605285767,\n",
       "  0.022471999999999999,\n",
       "  0.021495733701365021,\n",
       "  0.017907237303392165,\n",
       "  0.020839675483077948,\n",
       "  0.020099567836150113,\n",
       "  0.025622022152827831,\n",
       "  0.022917033301891418,\n",
       "  0.018935243770281912,\n",
       "  0.016126693826076066,\n",
       "  0.017907237303392168,\n",
       "  0.014389100786359096,\n",
       "  0.015487757177848576,\n",
       "  0.015487757177848576,\n",
       "  0.01564993706824408,\n",
       "  0.017187774976418563,\n",
       "  0.017187774976418563,\n",
       "  0.017187774976418563,\n",
       "  0.017622977392029993,\n",
       "  0.017551193071697439,\n",
       "  0.019001800192613338,\n",
       "  0.019783019425760072,\n",
       "  0.019783019425760072,\n",
       "  0.019134218520754906,\n",
       "  0.019134218520754906,\n",
       "  0.018935243770281916,\n",
       "  0.018256339102897937,\n",
       "  0.01612669382607607,\n",
       "  0.01612669382607607,\n",
       "  0.01612669382607607,\n",
       "  0.01564993706824408,\n",
       "  0.019001800192613327,\n",
       "  0.019001800192613327,\n",
       "  0.019001800192613327,\n",
       "  0.018256339102897926,\n",
       "  0.017907237303392168,\n",
       "  0.017907237303392168,\n",
       "  0.016665681240201371,\n",
       "  0.018256339102897926,\n",
       "  0.018256339102897926,\n",
       "  0.018256339102897926,\n",
       "  0.018325361425085181,\n",
       "  0.016126693826076066,\n",
       "  0.016126693826076066,\n",
       "  0.015323860954733301,\n",
       "  0.015730399999999992,\n",
       "  0.017040237697872641,\n",
       "  0.017040237697872641,\n",
       "  0.015730399999999992,\n",
       "  0.01564993706824408,\n",
       "  0.017907237303392168,\n",
       "  0.016665681240201378,\n",
       "  0.017907237303392168,\n",
       "  0.017907237303392165,\n",
       "  0.017907237303392165,\n",
       "  0.017977599999999993,\n",
       "  0.016816504959116799,\n",
       "  0.016048217964621487,\n",
       "  0.016891411810739797,\n",
       "  0.019001800192613327,\n",
       "  0.017907237303392165,\n",
       "  0.016513480049947078,\n",
       "  0.014389100786359096,\n",
       "  0.01532386095473331,\n",
       "  0.01532386095473331,\n",
       "  0.014389100786359096,\n",
       "  0.01532386095473331,\n",
       "  0.019331145340098187,\n",
       "  0.016126693826076063,\n",
       "  0.017977599999999993,\n",
       "  0.020900168137122723,\n",
       "  0.018598889403402562,\n",
       "  0.018598889403402562,\n",
       "  0.018598889403402562,\n",
       "  0.018117505611976503,\n",
       "  0.018598889403402555,\n",
       "  0.018598889403402555,\n",
       "  0.018598889403402555],\n",
       " 'train-error-mean': [0.18792139999999999,\n",
       "  0.18764059999999999,\n",
       "  0.18764039999999998,\n",
       "  0.18567420000000001,\n",
       "  0.18595499999999998,\n",
       "  0.18539339999999999,\n",
       "  0.18707860000000001,\n",
       "  0.18707860000000004,\n",
       "  0.18455059999999998,\n",
       "  0.18426959999999998,\n",
       "  0.18483160000000001,\n",
       "  0.18455060000000001,\n",
       "  0.18455060000000001,\n",
       "  0.18455060000000001,\n",
       "  0.18539320000000001,\n",
       "  0.18539320000000001,\n",
       "  0.18455060000000004,\n",
       "  0.18286520000000001,\n",
       "  0.18370780000000003,\n",
       "  0.18342700000000001,\n",
       "  0.18230339999999998,\n",
       "  0.1831458,\n",
       "  0.18258440000000001,\n",
       "  0.18117980000000003,\n",
       "  0.17921339999999999,\n",
       "  0.17668520000000001,\n",
       "  0.17499999999999999,\n",
       "  0.17191020000000001,\n",
       "  0.17134840000000001,\n",
       "  0.166573,\n",
       "  0.16404460000000001,\n",
       "  0.16235920000000001,\n",
       "  0.16292100000000001,\n",
       "  0.16179759999999999,\n",
       "  0.16151679999999996,\n",
       "  0.16151679999999996,\n",
       "  0.16095499999999999,\n",
       "  0.16039300000000001,\n",
       "  0.15983120000000001,\n",
       "  0.16039319999999999,\n",
       "  0.16039300000000001,\n",
       "  0.16067400000000001,\n",
       "  0.15983139999999998,\n",
       "  0.15758420000000001,\n",
       "  0.1570222,\n",
       "  0.15674139999999998,\n",
       "  0.15674159999999998,\n",
       "  0.15617980000000001,\n",
       "  0.15505600000000003,\n",
       "  0.1544942,\n",
       "  0.1542134,\n",
       "  0.15421319999999999,\n",
       "  0.15449419999999997,\n",
       "  0.1542134,\n",
       "  0.15393239999999997,\n",
       "  0.15365160000000003,\n",
       "  0.15308959999999999,\n",
       "  0.15337079999999997,\n",
       "  0.15280900000000003,\n",
       "  0.1519662,\n",
       "  0.15140419999999999,\n",
       "  0.15168500000000001,\n",
       "  0.15140440000000002,\n",
       "  0.15028079999999999,\n",
       "  0.15196599999999999,\n",
       "  0.15168519999999999,\n",
       "  0.14887619999999999,\n",
       "  0.14831440000000001,\n",
       "  0.14775260000000001,\n",
       "  0.14747180000000001,\n",
       "  0.14775259999999998,\n",
       "  0.14691000000000001,\n",
       "  0.14691000000000001,\n",
       "  0.14606720000000001,\n",
       "  0.14691000000000001,\n",
       "  0.14550560000000001,\n",
       "  0.14634820000000001,\n",
       "  0.14634819999999998,\n",
       "  0.14578640000000001,\n",
       "  0.14719080000000001,\n",
       "  0.14691000000000001,\n",
       "  0.14578640000000001,\n",
       "  0.14606740000000001,\n",
       "  0.14550540000000001,\n",
       "  0.14550540000000001,\n",
       "  0.14634799999999998,\n",
       "  0.14522459999999998,\n",
       "  0.14494360000000001,\n",
       "  0.14550560000000001,\n",
       "  0.14410100000000001,\n",
       "  0.143258,\n",
       "  0.14353920000000001,\n",
       "  0.14382,\n",
       "  0.14297739999999998,\n",
       "  0.14213480000000001,\n",
       "  0.1426964,\n",
       "  0.14297719999999997,\n",
       "  0.1426962,\n",
       "  0.1432582,\n",
       "  0.14185379999999997],\n",
       " 'train-error-std': [0.0062432155368848177,\n",
       "  0.0037263937848810262,\n",
       "  0.0045813648883274924,\n",
       "  0.0042967607054617248,\n",
       "  0.004222826352101158,\n",
       "  0.0043514904389185946,\n",
       "  0.0044766712901440431,\n",
       "  0.0037051587064523901,\n",
       "  0.0053739020683298581,\n",
       "  0.0054323371250319082,\n",
       "  0.0016851999999999978,\n",
       "  0.0019050680407796477,\n",
       "  0.0019050680407796477,\n",
       "  0.0019050680407796477,\n",
       "  0.0023500585013994878,\n",
       "  0.0023500585013994878,\n",
       "  0.0036189415358637684,\n",
       "  0.0037053406537051348,\n",
       "  0.0051336457766386658,\n",
       "  0.004031715267724144,\n",
       "  0.0042968653039163395,\n",
       "  0.0032758287745240965,\n",
       "  0.0017767257075868605,\n",
       "  0.0019862629634567561,\n",
       "  0.0028920813681499323,\n",
       "  0.0040120264904409562,\n",
       "  0.0026050241457614208,\n",
       "  0.0057292681347620679,\n",
       "  0.0025123341815928828,\n",
       "  0.0036190346779217289,\n",
       "  0.0028646291627364207,\n",
       "  0.002102063119889596,\n",
       "  0.0017765675894825905,\n",
       "  0.0027231996327849377,\n",
       "  0.0026646405686321021,\n",
       "  0.0026646405686321021,\n",
       "  0.0026048084766446835,\n",
       "  0.0028645703342735336,\n",
       "  0.0031279341041652369,\n",
       "  0.0027232408927599485,\n",
       "  0.0031278263378902538,\n",
       "  0.0028920036652812157,\n",
       "  0.0037054619469102678,\n",
       "  0.0058520496716962323,\n",
       "  0.005359209471554543,\n",
       "  0.0050716375501409774,\n",
       "  0.0052998410013886214,\n",
       "  0.004387644625536577,\n",
       "  0.0059323693411654664,\n",
       "  0.0051026918151109305,\n",
       "  0.0051335144530818329,\n",
       "  0.0050560666688642536,\n",
       "  0.0052549974462410606,\n",
       "  0.0049774929673481218,\n",
       "  0.0052251710632284553,\n",
       "  0.0064423282313151291,\n",
       "  0.0056181500015574492,\n",
       "  0.006050613337505545,\n",
       "  0.0052097786901172671,\n",
       "  0.0055757662576546314,\n",
       "  0.005504523972152362,\n",
       "  0.0056180000000000015,\n",
       "  0.0051338427556753214,\n",
       "  0.0056878902732032319,\n",
       "  0.0056461395306882005,\n",
       "  0.0056878902732032345,\n",
       "  0.0056876927272840579,\n",
       "  0.0057979238560022569,\n",
       "  0.0051334050142181386,\n",
       "  0.0047834371909747028,\n",
       "  0.0049777186983597232,\n",
       "  0.0038309359169790298,\n",
       "  0.0040315759201582707,\n",
       "  0.0047833197426055442,\n",
       "  0.0061926729608465497,\n",
       "  0.0048327747143851003,\n",
       "  0.0046497948513886094,\n",
       "  0.004816443351685973,\n",
       "  0.0046495290342141058,\n",
       "  0.0037054922695911839,\n",
       "  0.0042229593888646411,\n",
       "  0.0046497706868188675,\n",
       "  0.004529500440445945,\n",
       "  0.0044058336146522853,\n",
       "  0.0045813648883274959,\n",
       "  0.0045640478525098734,\n",
       "  0.0040314923093068096,\n",
       "  0.0046497706868188684,\n",
       "  0.0044943875044326119,\n",
       "  0.0050719255515040808,\n",
       "  0.0061542106561280393,\n",
       "  0.004977628407183487,\n",
       "  0.0055186871989631701,\n",
       "  0.004977492967348114,\n",
       "  0.0043879007007907511,\n",
       "  0.0049136517011281865,\n",
       "  0.0047337872111027478,\n",
       "  0.0048327863350245415,\n",
       "  0.0054034273345720139,\n",
       "  0.0046157188562562998]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prob2bool(l):\n",
    "    if l>0.5:\n",
    "        return 1\n",
    "    return 0\n",
    "result=sc.parallelize(preds).map(prob2bool).zipWithIndex().map(lambda x: (str(x[1]+892)+\",\"+str(x[0])+\"\\n\"))\n",
    "a=result.collect()\n",
    "file_object = open('thefile4.csv', 'w')\n",
    "file_object.write(\"PassengerId,Survived\\n\")\n",
    "file_object.writelines(a)\n",
    "file_object.close( )\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(preds).map(prob2bool).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(preds).map(prob2bool).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(preds).map(prob2bool).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Spark 2.0.0)",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
